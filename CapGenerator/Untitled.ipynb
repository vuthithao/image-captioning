{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "import cv2\n",
    "import load_data as ld\n",
    "import generate_model as gen\n",
    "import argparse\n",
    "\n",
    "# extract features from each photo in the directory\n",
    "def extract_features(filename):\n",
    "    # load the model\n",
    "    model = VGG16()\n",
    "    # re-structure the model\n",
    "    model.layers.pop()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    # load the photo\n",
    "\n",
    "    image = load_img(filename, target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "#     print(image)\n",
    "    # reshape data for the model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    # get features\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    return feature\n",
    "\n",
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, index_word, max_length, beam_size=5):\n",
    "\n",
    "  captions = [['startseq', 0.0]]\n",
    "  # seed the generation process\n",
    "  in_text = 'startseq'\n",
    "  # iterate over the whole length of the sequence\n",
    "  for i in range(max_length):\n",
    "    all_caps = []\n",
    "    # expand each current candidate\n",
    "    for cap in captions:\n",
    "      sentence, score = cap\n",
    "      # if final word is 'end' token, just add the current caption\n",
    "      if sentence.split()[-1] == 'endseq':\n",
    "        all_caps.append(cap)\n",
    "        continue\n",
    "      # integer encode input sequence\n",
    "      sequence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "      # pad input\n",
    "      sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "      # predict next words\n",
    "      y_pred = model.predict([photo,sequence], verbose=0)[0]\n",
    "      # convert probability to integer\n",
    "      yhats = np.argsort(y_pred)[-beam_size:]\n",
    "\n",
    "      for j in yhats:\n",
    "        # map integer to word\n",
    "        word = index_word.get(j)\n",
    "        # stop if we cannot map the word\n",
    "        if word is None:\n",
    "          continue\n",
    "        # Add word to caption, and generate log prob\n",
    "        caption = [sentence + ' ' + word, score + np.log(y_pred[j])]\n",
    "        all_caps.append(caption)\n",
    "\n",
    "    # order all candidates by score\n",
    "    ordered = sorted(all_caps, key=lambda tup:tup[1], reverse=True)\n",
    "    captions = ordered[:beam_size]\n",
    "\n",
    "  return captions\n",
    "\n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, descriptions, photos, tokenizer, index_word, max_length):\n",
    "  actual, predicted = list(), list()\n",
    "  # step over the whole set\n",
    "  for key, desc_list in descriptions.items():\n",
    "    # generate description\n",
    "    yhat = generate_desc(model, tokenizer, photos[key], index_word, max_length)[0]\n",
    "    # store actual and predicted\n",
    "    references = [d.split() for d in desc_list]\n",
    "    actual.append(references)\n",
    "    # Use best caption\n",
    "    predicted.append(yhat[0].split())\n",
    "  # calculate BLEU score\n",
    "  print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "  print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "  print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "  print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "def eval_test_set(model, descriptions, photos, tokenizer, index_word, max_length):\n",
    "  actual, predicted = list(), list()\n",
    "  # step over the whole set\n",
    "  for key, desc_list in descriptions.items():\n",
    "    # generate description\n",
    "    yhat = generate_desc(model, tokenizer, photos[key], index_word, max_length)[0]\n",
    "    # store actual and predicted\n",
    "    references = [d.split() for d in desc_list]\n",
    "    actual.append(references)\n",
    "    # Use best caption\n",
    "    predicted.append(yhat[0].split())\n",
    "  predicted = sorted(predicted)\n",
    "  actual = [x for _,x in sorted(zip(actual,predicted))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0702 02:16:42.775471 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:529: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0702 02:16:42.809324 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0702 02:16:42.811180 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:136: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0702 02:16:42.823193 139980607653696 deprecation.py:506] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3721: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0702 02:16:42.848180 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4420: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0702 02:16:43.131627 139980607653696 deprecation.py:323] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3227: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0702 02:16:45.074975 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:178: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0702 02:16:45.664510 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('/media/thaovt6/DATA/build_data/Image-Captioning/models/tokenizer.pkl', 'rb'))\n",
    "index_word = load(open('/media/thaovt6/DATA/build_data/Image-Captioning/models/index_word.pkl', 'rb'))\n",
    "# pre-define the max sequence length (from training)\n",
    "max_length = 34\n",
    "\n",
    "filename = '/media/thaovt6/DATA/build_data/Image-Captioning/models/model_weight.h5'\n",
    "model = load_model(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0702 02:16:50.943610 139980607653696 deprecation_wrapper.py:119] From /home/thaovt6/yes/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4255: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def caption(imgpath):\n",
    "    imgpath= \"/home/thaovt6/Downloads/index.jpeg\"\n",
    "    photo = extract_features(imgpath)\n",
    "    # generate description\n",
    "    captions = generate_desc(model, tokenizer, photo, index_word, max_length)\n",
    "    caption = captions[0][0].split()[1:-1]\n",
    "    caption = ' '.join(caption)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the blonde boy is smiling'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
